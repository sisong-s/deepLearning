{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ee5c5c-92f5-4bab-abcf-109a4c1b1659",
   "metadata": {},
   "source": [
    "Q=AW_Q \n",
    "K=AW_K\n",
    "V=AW_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cbb0aae-3608-4982-a9d6-b24413fa5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e057fb-fdb1-4ead-9c47-302095b073a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value = 0):\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype = torch.float32, device = X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value # ~mask取反，将无效特征位置设为value（默认0）\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d13fdc-2cd3-4311-b697-e5eb8d8e6cfc",
   "metadata": {},
   "source": [
    "生成0到maxlen-1的序列（特征位置索引），形状为(1, maxlen)\n",
    "arange = torch.arange(maxlen, dtype=torch.float32, device=X.device)[None, :]\n",
    "\n",
    "valid_len[:, None] 将(6,)的valid_len扩展为(6, 1)，适配特征维度\n",
    "mask = arange < valid_len[:, None]  # 形状为(6, maxlen)，即(6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91768e1-881f-41f8-b871-4ddf0335b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_lens):\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim = -1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value = -1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6145fdab-4e15-47b3-b9b5-015137c67448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5050, 0.4950, 0.0000, 0.0000],\n",
       "         [0.5753, 0.4247, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.3858, 0.3640, 0.2502, 0.0000],\n",
       "         [0.4396, 0.3210, 0.2394, 0.0000]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dda74f63-3c79-45fb-9c26-a2ae8e0b8ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4643, 0.3452, 0.1905, 0.0000]],\n",
       "\n",
       "        [[0.4110, 0.5890, 0.0000, 0.0000],\n",
       "         [0.3208, 0.3391, 0.1516, 0.1885]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e54da-90b0-41ae-90aa-6e52d5aa9c05",
   "metadata": {},
   "source": [
    "若 valid_lens 是 1D（每个样本一个有效长度）：通过 repeat_interleave 重复 shape[1] 次（shape[1] 是序列长度），让每个位置都对应相同的有效长度。\n",
    "valid_lens 是 1D 张量，形状为 (batch_size,)，例如 valid_lens = torch.tensor([2, 3])（表示 batch 中两个样本的有效长度分别为 2 和 3）。\n",
    "shape[1] 是输入 X 的序列长度（第二维），例如 shape = (2, 4, 5)，则 shape[1] = 4（每个样本包含 4 个序列元素）。\n",
    "原 valid_lens 中的第一个元素 2 被重复 shape[1] = 4 次 → [2, 2, 2, 2]。\n",
    "原 valid_lens 中的第二个元素 3 被重复 shape[1] = 4 次 → [3, 3, 3, 3]。\n",
    "tensor([2, 2, 2, 2, 3, 3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3583895a-dd99-4439-aa25-f80a922aaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, key, values, valid_lens = None):\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34477829-2fe4-4aff-b2ab-64679871ac51",
   "metadata": {},
   "source": [
    "简单说：bmm 是 “专用批量矩阵乘法工具”，而 matmul 是 “通用矩阵乘法瑞士军刀”。在明确处理 3 维批量矩阵且无需广播时，bmm 更直观；其他情况（尤其是高维或需要广播时）用 matmul。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b839551-5e5f-444c-9a48-c7cfef180088",
   "metadata": {},
   "source": [
    "在 Python 中，**kwargs 是一种特殊的参数语法，用于处理函数调用时传入的关键字参数（key-value 形式的参数），并将这些参数打包成一个字典（dictionary）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2862ca4d-6abd-487d-831a-86817053baee",
   "metadata": {},
   "source": [
    "在 PyTorch 中，torch.matmul(queries, keys.transpose(-2, -1)) 的矩阵乘法维度匹配遵循最后两个维度相乘的规则，这与多头注意力中 “每个头独立计算注意力分数” 的逻辑完全契合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09fca68-38b6-4b41-8ccb-295e11200deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
       "\n",
       "        [[10.0000, 11.0000, 12.0000, 13.0000]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = torch.normal(0, 1, (2, 1, 2))\n",
    "keys = torch.ones((2, 10, 2))\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(\n",
    "    2, 1, 1)\n",
    "valid_lens = torch.tensor([2, 6])\n",
    "attention = DotProductAttention(dropout = 0.5)\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ef340-ee10-4b21-ae3d-a09ec46727a1",
   "metadata": {},
   "source": [
    "最后 .repeat(2, 1, 1)：\n",
    "对张量进行重复操作，参数 (2, 1, 1) 表示：\n",
    "第一个维度重复 2 次\n",
    "第二个维度重复 1 次（保持不变）\n",
    "第三个维度重复 1 次（保持不变）\n",
    "最终得到的张量形状为 (2, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb9755-3d29-42a2-943d-2d1993215ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, num_heads, dropout, bias = False, **kwargs):\n",
    "        super(MutiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = d2l.DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias = bias) # query_size 指的是 输入X的 最后一维\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias = bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias =bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias = bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5295765f-5f31-4f96-b92f-5b51e9b765f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于位置的前馈网络\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d8ee35-2abb-4ad7-b67a-86863c1c2100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2, 3, 4))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86598188-cdce-43c4-9489-e6cc0ee182c3",
   "metadata": {},
   "source": [
    "在 PyTorch 中，nn.Linear 层（全连接层）虽然本质上处理的是二维特征（[batch_size, feature_dim]），但它对输入的前导维度（batch 维度）具有兼容性，会自动忽略除最后一个维度之外的所有维度，只对最后一个维度进行线性变换。\n",
    "\n",
    "只关注输入的最后一个维度（即 feature_dim=4），前面的所有维度（2 和 3）会被视为 “批量维度”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d176a34-367f-468e-83c3-0d3aaa132c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3013,  0.2407,  0.1331,  0.2597, -0.1420,  0.2759, -0.2957,  0.0645],\n",
       "        [ 0.3013,  0.2407,  0.1331,  0.2597, -0.1420,  0.2759, -0.2957,  0.0645],\n",
       "        [ 0.3013,  0.2407,  0.1331,  0.2597, -0.1420,  0.2759, -0.2957,  0.0645]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn(torch.ones((2, 3, 4)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c75022f0-252d-422e-9c09-8acb64a78bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \n",
      "batch norm: tensor([[-1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 对比不同维度的层规范化和批量规范化的效果\n",
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)\n",
    "X = torch.tensor([[1, 2], [2, 3]], dtype = torch.float32)\n",
    "print('layer norm:', ln(X), '\\nbatch norm:', bn(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a9e0f-545a-453d-82cf-6ef5efc3dafa",
   "metadata": {},
   "source": [
    "type：描述变量本身的类型（即变量是哪种对象）。\n",
    "例如：整数、字符串、列表，或 PyTorch 中的 Tensor、nn.Module 等。\n",
    "\n",
    "\n",
    "dtype：仅用于数值型对象（如数组、张量），描述对象内部存储的数据的类型（即元素的数值类型）。\n",
    "例如：整数是 32 位还是 64 位，浮点数是单精度还是双精度等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4748b08-a394-494a-a69f-c219c5e580c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差连接和层规范化\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        return self.ln(self.dropout(y) + X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f519ea48-a705-41b4-9dd0-1a96385e4809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm([3, 4], 0.5)\n",
    "add_norm.eval()\n",
    "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d2f00-7f07-47a7-b5fb-1eeee1133f5f",
   "metadata": {},
   "source": [
    "必须确保 normalized_shape 与输入张量的最后 N 个维度完全匹配（N 是 normalized_shape 的长度），否则会报错。\n",
    "\n",
    "例如：\n",
    "\n",
    "若输入是 (32, 50, 256)，normalized_shape=256（或 (256,)）是正确的；\n",
    "若错误设为 normalized_shape=50，则会因 “输入最后 1 个维度是 256，与 50 不匹配” 报错。\n",
    "\n",
    "(256,) 表示一个只包含一个元素的元组（tuple），其中唯一的元素是整数 256。\n",
    "\n",
    "这个写法的关键是末尾的逗号 ,，它用来区分 “单个元素的元组” 和 “用括号包裹的普通数值”：\n",
    "\n",
    "(256) 只是带括号的整数 256，不是元组\n",
    "(256,) 才是包含 256 这一个元素的元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42400bc9-1b8c-463d-adfc-cdff149670f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码器\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = multiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, ffn_num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddc51427-5719-43d4-99d3-df85bb7e8687",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiHeadAttention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m24\u001b[39m))\n\u001b[0;32m      2\u001b[0m valid_lens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m encoder_blk \u001b[38;5;241m=\u001b[39m \u001b[43mEncoderBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m encoder_blk\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      5\u001b[0m encoder_blk(X, valid_lens)\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mEncoderBlock.__init__\u001b[1;34m(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias, **kwargs)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m(EncoderBlock, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention \u001b[38;5;241m=\u001b[39m \u001b[43mmultiHeadAttention\u001b[49m(key_size, query_size, value_size, num_hiddens, num_heads, dropout, use_bias)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddnorm1 \u001b[38;5;241m=\u001b[39m AddNorm(norm_shape, dropout)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn \u001b[38;5;241m=\u001b[39m PositionWiseFFN(ffn_num_input, ffn_num_hiddens, ffn_num_hiddens)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multiHeadAttention' is not defined"
     ]
    }
   ],
   "source": [
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b481466-583b-4d5c-8df0-0f7381af8ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
