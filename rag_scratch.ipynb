{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb30cc3-e451-4989-bfab-572290b859da",
   "metadata": {},
   "source": [
    "环境准备\n",
    "%pip install datasets langchain sentence_transformers tqdm chromadb langchain_wenxin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8232bb-6bd9-4dc5-a376-6459a3701e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\administered\\\\ai\\\\deepLearning\\\\li.txt'}, page_content='藜（读音lí）麦（Chenopodium\\\\xa0quinoa\\\\xa0Willd.）是藜科藜属植物。穗部可呈红、紫、黄，植株形状类似灰灰菜，成熟后穗部类似高粱穗。植株大小受环境及遗传因素影响较大，从0.3-3米不等，茎部质地较硬，可分枝可不分。单叶互生，叶片呈鸭掌状，叶缘分为全缘型与锯齿缘型。藜麦花两性，花序呈伞状、穗状、圆锥状，藜麦种子较小，呈小圆药片状，直径1.5-2毫米，千粒重1.4-3克。\\\\xa0[1]\\\\xa0\\\\n原产于南美洲安第斯山脉的哥伦比亚、厄瓜多尔、秘鲁等中高海拔山区。具有一定的耐旱、耐寒、耐盐性，生长范围约为海平面到海拔4500米左右的高原上，最适的高度为海拔3000-4000米的高原或山地地区。\\\\xa0[1]\\\\xa0\\\\n藜麦富含的维生素、多酚、类黄酮类、皂苷和植物甾醇类物质具有多种健康功效。')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 本地数据加载\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"C:\\\\Users\\\\administered\\\\ai\\\\deepLearning\\\\li.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b74228d6-edcb-48cc-a4fa-6bd92ebf1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 \n",
      " [Document(metadata={'source': 'C:\\\\Users\\\\administered\\\\ai\\\\deepLearning\\\\li.txt'}, page_content='藜（读音lí）麦（Chenopodium\\\\xa0quinoa\\\\xa0Willd.）是藜科藜属植物。穗部可呈红、紫、黄，植株形状类似灰灰菜，成熟后穗部类似高粱穗。植株大小受环境及遗传因素影响较大，从0.3-3米不等，茎部质地较硬，可分枝可不分'), Document(metadata={'source': 'C:\\\\Users\\\\administered\\\\ai\\\\deepLearning\\\\li.txt'}, page_content='。单叶互生，叶片呈鸭掌状，叶缘分为全缘型与锯齿缘型。藜麦花两性，花序呈伞状、穗状、圆锥状，藜麦种子较小，呈小圆药片状，直径1.5-2毫米，千粒重1.4-3克。\\\\xa0[1]\\\\xa0\\\\n原产于南美洲安第斯山脉的哥伦比亚、厄瓜多尔、秘鲁等中高海拔山区'), Document(metadata={'source': 'C:\\\\Users\\\\administered\\\\ai\\\\deepLearning\\\\li.txt'}, page_content='。具有一定的耐旱、耐寒、耐盐性，生长范围约为海平面到海拔4500米左右的高原上，最适的高度为海拔3000-4000米的高原或山地地区。\\\\xa0[1]\\\\xa0\\\\n藜麦富含的维生素、多酚、类黄酮类、皂苷和植物甾醇类物质具有多种健康功效。')]\n"
     ]
    }
   ],
   "source": [
    "# 文档分割\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 采用固定字符长度分割chunk_size=128\n",
    "# 自定义中文分隔符（按优先级排序）\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=128,          # 最大字符数\n",
    "    chunk_overlap=0,         # 片段重叠数\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \"，\", \"；\", \"、\"]  # 中文优先分割符\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(documents)\n",
    "documents\n",
    "print(len(documents[0].page_content),'\\n', documents)  # 输出文本的字符数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f2d65-c9b5-412f-bf3b-4d6282bc1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接下来对分割后的数据进行embedding，并写入数据库。这里选用m3e-base作为embedding模型，向量数据库选用Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name = \"moka-ai/m3e-base\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = model_kwargs\n",
    "    encode_kwargs = encode_kwargs\n",
    "    query_instruction = \"为文本生成向量表示用于文本检索\"              \n",
    ")\n",
    "\n",
    "db = Chroma.from_documents(documents, embedding)\n",
    "db.similarity_search('藜一般在几月播种?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87ea4b-1b3c-4fe4-a592-07bfbd8af807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt设计\n",
    "template = '''\n",
    "        【任务描述】\n",
    "        请根据用户输入的上下文回答问题，并遵守回答要求。\n",
    "\n",
    "        【背景知识】\n",
    "        {{context}}\n",
    "\n",
    "        【回答要求】\n",
    "        - 你需要严格根据背景知识的内容回答，禁止根据常识和已知信息回答问题。\n",
    "        - 对于不知道的信息，直接回答“未找到相关答案”\n",
    "        -----------\n",
    "        {question}\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb49061-e4b0-425b-bc03-da7aeddb7116",
   "metadata": {},
   "source": [
    "这里采用ConversationalRetrievalChain，ConversationalRetrievalQA chain 是建立在 RetrievalQAChain 之上，提供历史聊天记录组件。如下面定义了memory来追踪聊天记录，在流程上，先将历史问题和当前输入问题融合为一个新的独立问题，然后再进行检索，获取问题相关知识，最后将获取的知识和生成的新问题注入Prompt让大模型生成回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b91020-87c6-4b0a-9a9d-c3ccb7585970",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/root-validator-pre-skip",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_wenxin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Wenxin\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversationBufferMemory\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\langchain_wenxin\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SPDX-FileCopyrightText: 2023-present Tao Yang <swulling@gmail.com>\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: MIT\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_wenxin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatWenxin  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_wenxin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WenxinClient  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_wenxin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WenxinEmbeddings  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\langchain_wenxin\\chat_models.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGenerationChunk\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Extra\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_wenxin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaiduCommon\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mChatWenxin\u001b[39;00m(BaseChatModel, BaiduCommon):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper around Baidu Wenxin's large language model.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    To use, you should have the environment variable ``BAIDU_API_KEY`` and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m            response = model(\"What are the biggest risks facing humanity?\")\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\langchain_wenxin\\llms.py:20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_wenxin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WenxinClient\n\u001b[0;32m     17\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBaiduCommon\u001b[39;00m(BaseModel):\n\u001b[0;32m     21\u001b[0m     client: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m#: :meta private:\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mernie-bot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\langchain_wenxin\\llms.py:52\u001b[0m, in \u001b[0;36mBaiduCommon\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m baidu_secret_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Baidu Cloud secret key.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_environment\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:  \u001b[38;5;66;03m# noqa: N805\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate that api key and python package exists in environment.\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     baidu_api_key \u001b[38;5;241m=\u001b[39m get_from_dict_or_env(\n\u001b[0;32m     56\u001b[0m         values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaidu_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAIDU_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m     )\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\pydantic\\deprecated\\class_validators.py:240\u001b[0m, in \u001b[0;36mroot_validator\u001b[1;34m(pre, skip_on_failure, allow_reuse, *__args)\u001b[0m\n\u001b[0;32m    238\u001b[0m mode: Literal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pre \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m skip_on_failure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    243\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot-validator-pre-skip\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    246\u001b[0m wrap \u001b[38;5;241m=\u001b[39m partial(_decorators_v1\u001b[38;5;241m.\u001b[39mmake_v1_generic_root_validator, pre\u001b[38;5;241m=\u001b[39mpre)\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdec\u001b[39m(f: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mclassmethod\u001b[39m[Any, Any, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstaticmethod\u001b[39m[Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/root-validator-pre-skip"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_wenxin.llms import Wenxin\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# llm选型\n",
    "llm = Wenxin(model = 'ernie-bot', baidu_api_key = 'baidu_api_key', baidu_secret_key = 'baidu_secret_key')\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "memory = ConversationBufferMemory(memory_key = 'chat_history', return_messages = True)\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever, memory = memory)\n",
    "qa({\"question\": \"藜怎么防治虫害？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d10ea-800f-47f8-a903-4a08390b129b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
